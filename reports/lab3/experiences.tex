\chapter{Experiences and Time Spent}\label{chap:exp}
\section{Duane's Summary}
The majority of my time this week was spent optimizing our $A^*$ algorithm.  Our original implementation was entirely in Ruby, but it turned out to be too slow for discretization below 40 meters or so.  The new code is a Ruby extension written in C, and performs much better (1/2 second compared with 45 seconds).
\par
I also refactored our agent code to use state transitions for this lab.  Rather than using several different Agent classes for each task (e.g. a `dummy' agent vs a `smart' agent), we unified our code into a single agent that could make decisions regarding states.  Once this refactoring was in place, Jon Brandenburg specialized our agents for sniper and decoy capabilities.
\par
I spent about 15 hours on this project, divided as follows:
\begin{itemize}
    \item 8 hours implementing a fast $A^*$ algorithm in C
    \item 3 hours refactoring our agents to use state information
    \item 2 hours debugging and passing off with another team in the CS Sports lab.
    \item 2 hours writing this report and formatting it in \LaTeX
\end{itemize}

\section{Michael's Summary}
This lab was especially fun because once again we got to see our agents take action in the bzflags world.  We now had the ability to see what our agents were 'thinking' by generating PDF maps of how they saw the world and we also had the ability to watch them act by joining the bzflag world as an observer.  This made it much more insteresting to work on because we could see immediate results.
\par
Duane was the first to make serious progress with his $A*$ module written in C.  This gave Jon and I a good place to start implementing out parts.  I focused on implementing the path-following code and using potential fields.  The original implementation would always place an attractive potential field on the next node in the solution path, but that made our agents very slow and tentative because the individual path segments were very small. This gave rise to the idea of placing the attractive field further ahead.  This eventually turned into 
\par
The night I stayed up late working on $A^*$ I made a costly error of assuming that the problem was in the execution of the algorithm.  This meant that I spent hours of time looking at the algorithm trying to figure out what was wrong before I realized that the problem was my bookkeeping.  The fringe list was stored with references to each chunk on the map so when I re-encountered that same node its path-cost and heuristic were updated and changed which affected when it would be popped off.  Once I found the problem the algorithm magically started to work!
\par
In the end I spent a total of about 20 hours split across the following tasks:
\begin{itemize}
    \item 4 hours of re-working code from last lab to try to make our ``smart'' agents notice when the position of the flag has changed.
    \item 2 hours playing with algorithms to find if a point is inside an obstacle
    \item 4 hours of discretizing the map
    \item 3 hours implementing $A^*$
    \item 1 hour implementing \texttt{greedy best first}
    \item 2 hours finalizing and integrating code with Duane
    \item 4 hours passing off and preparing report material
\end{itemize}

\section{Jon's Summary}